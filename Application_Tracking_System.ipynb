{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH0SX5H8jBnXNPhtSYegZo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lovejeet-Singh-31/-ATS-Application-Tracking-System-/blob/main/Application_Tracking_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VkkYCNI7YXA",
        "outputId": "c2e87c8a-0574-48f7-e661-c2a407af7e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ENc-z9p_UIA",
        "outputId": "cdf5c67b-3f69-4b88-bffb-21ca50a39861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (2.12.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxsbY8E77Rsv",
        "outputId": "1b0bcf52-ccb9-499a-ddf4-1cd8733658d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The PDF file is 26.48% similar to the job role description.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Convert PDF to text\n",
        "import PyPDF2\n",
        "pdf_file = open('/content/drive/MyDrive/Lovejeet_Singh_2023.pdf', 'rb')\n",
        "pdf_reader = PyPDF2.PdfReader (pdf_file)\n",
        "text = ''\n",
        "for page in range(len(pdf_reader.pages)):\n",
        "    text += pdf_reader.pages[page].extract_text()\n",
        "\n",
        "# Step 2: Preprocess the text data\n",
        "import re\n",
        "text = re.sub(r'\\W+', ' ', text)  # remove non-alphanumeric characters\n",
        "text = text.lower()  # convert to lowercase\n",
        "\n",
        "# Step 3: Tokenize the text\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Step 4: Remove stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [token for token in tokens if not token in stop_words]\n",
        "\n",
        "# Step 5: Vectorize the text using TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform([' '.join(filtered_tokens)])\n",
        "\n",
        "# Step 6: Load job role description and vectorize it using the same technique\n",
        "job_description_1 = 'The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users. Understand the day-to-day issues that our business faces, which can be better understood with data. Compile and analyze data related to business issues Develop clear visualizations to convey complicated data in a straightforward fashion.'\n",
        "job_description_2 = \"Bachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience 1 - 2 years' Data Analysis experience Proficient in SQL\"\n",
        "job_description = job_description_1 + job_description_2\n",
        "job_desc_vector = vectorizer.transform([job_description])\n",
        "\n",
        "# Step 7: Compare vectorized text using cosine similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_score = cosine_similarity(X, job_desc_vector)[0][0]\n",
        "\n",
        "# Step 8: Calculate percentage similarity and return result\n",
        "percent_similarity = similarity_score * 100\n",
        "print(f\"The PDF file is {percent_similarity:.2f}% similar to the job role description.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FCMujLAz_k6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}